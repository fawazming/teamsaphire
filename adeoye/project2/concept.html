<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Concept of Large Language Models </title>
    <link rel="stylesheet" href="water.css">
</head>
<body>
    <center><h1>Large Language Models</h1></center>
    <p><b>LLMs</b> are sophisticated <b>AI</b> systems designed to understand and generate human language. Key concepts that underpin their functionality include <em><b>tokens, embeddings, attention mechanisms, prompt engineering,</b></em> and advanced learning techniques such as <em>zero-shot and few-shot learning</em></p>
    <h1>Fundamental Building Blocks
    </h1>    <ol>
        <li><b>Tokens:</b>  LLMs process text by dividing it into smaller units known as <b>tokens</b>. These can be entire words, parts of words, or even individual characters, depending on the specific model and the language being processed.
        </li>
        <li><b>Embeddings:</b> To facilitate understanding, words and sentences are converted into numerical representations called <b>embeddings</b>. These vectors (arrays of numbers) allow the model to interpret language as data.
        </li>
        <li><b>Attention Mechanism: </b> This crucial feature enables <b>LLMs</b> to focus on the most relevant segments of input text, which is essential for grasping context and relationships within the language.
        </li>
        <li><b>Transformer Architecture:</b> Most <b>LLMs</b> are built on the <b>transformer architecture</b>, which employs <em>self-attention </em>to process entire sequences of text simultaneously.
        </li> 
    </ol>
    <h1>Training and Learning
    </h1>
    <ol>
        <li><b>Pre-training:</b> LLMs undergo an initial phase of pre-training on vast amounts of text data using unsupervised learning techniques</li>
        <li> <b>Fine-tuning:</b> Following pre-training, LLMs can be fine-tuned on specific tasks or datasets through supervised learning, which further refines their performance for particular applications.
        </li>
        <li><b>Zero-shot Learning: </b> One of the remarkable capabilities of LLMs is their ability to perform tasks they have not been explicitly trained for, showcasing their generalization skills.
        </li>
        <li> <b>Few-shot Learning: </b> LLMs can also learn new tasks with minimal supervision, often requiring only a few examples to adapt effectively.
        </li>
    </ol>
    <h1>Prompt Engineering</h1>
    <ol>
        <li><b>Prompts:</b> The input text given to an <b>LLM</b> is referred to as a <b>prompt</b>. The effectiveness of the model's output is heavily influenced by the quality and clarity of this <b>prompt</b>.
        </li>
        <li><b>Prompt Engineering:</b> This involves the strategic crafting of <b>prompts</b> to steer the <b>LLM </b>towards generating the desired responses.
        </li>
    </ol>
    

   <center> <img src="concept.png" alt="" width="1000"></center><br>
    <center><button><a href="training.html" class="navigate-button"><b>Next page</b></a></button></center><br>
    <center><button><a href="history.html" class="navigate-button"><b>Previous page</b></a></button></center>
</body>
</html>